from google.colab import files
uploaded = files.upload()


import zipfile
import os

zip_path = 'dataset.zip'  # t√™n file sau khi t·∫£i l√™n
extract_path = 'hand_gesture_datasets'

with zipfile.ZipFile('/content/dataset_N7.zip', 'r') as zip_ref:
    zip_ref.extractall(extract_path)

# Ki·ªÉm tra th∆∞ m·ª•c con b√™n trong
os.listdir(extract_path)


import torch
import torch.nn as nn
from torchvision import datasets, transforms, models
from torch.utils.data import DataLoader
from torch.optim import lr_scheduler
import time
import os

# === C·∫§U H√åNH ===
data_dir = "/content/hand_gesture_datasets/dataset_N7"  # Thay b·∫±ng ƒë∆∞·ªùng d·∫´n th∆∞ m·ª•c th·∫≠t c·ªßa b·∫°n
batch_size = 32
num_epochs = 10
learning_rate = 0.001
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# === TI·ªÄN X·ª¨ L√ù ·∫¢NH (AUGMENTATION) ===
transform = {
    "train": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ]),
    "val": transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize([0.5], [0.5])
    ])
}

# === T·∫¢I D·ªÆ LI·ªÜU ===
train_dataset = datasets.ImageFolder(os.path.join(data_dir, 'train'), transform=transform['train'])
val_dataset = datasets.ImageFolder(os.path.join(data_dir, 'val'), transform=transform['val'])

train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)
dataloaders = {'train': train_loader, 'val': val_loader}
class_names = train_dataset.classes

# === KH·ªûI T·∫†O M√î H√åNH (RESNET34) ===
model = models.resnet34(pretrained=True)
model.fc = nn.Linear(model.fc.in_features, len(class_names))
model = model.to(device)

# === H√ÄM M·∫§T M√ÅT, T·ªêI ∆ØU, SCHEDULER ===
criterion = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)
scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)

# === H√ÄM HU·∫§N LUY·ªÜN ===
def train_model(model, criterion, optimizer, scheduler, num_epochs=20):
    since = time.time()
    best_acc = 0.0
    best_model_wts = model.state_dict()

    for epoch in range(num_epochs):
        print(f"\nEpoch {epoch+1}/{num_epochs}")
        print("-" * 20)

        for phase in ['train', 'val']:
            model.train() if phase == 'train' else model.eval()
            running_loss = 0.0
            running_corrects = 0

            for inputs, labels in dataloaders[phase]:
                inputs = inputs.to(device)
                labels = labels.to(device)

                optimizer.zero_grad()
                with torch.set_grad_enabled(phase == 'train'):
                    outputs = model(inputs)
                    _, preds = torch.max(outputs, 1)
                    loss = criterion(outputs, labels)

                    if phase == 'train':
                        loss.backward()
                        optimizer.step()

                running_loss += loss.item() * inputs.size(0)
                running_corrects += torch.sum(preds == labels.data)

            if phase == 'train':
                scheduler.step()

            epoch_loss = running_loss / len(dataloaders[phase].dataset)
            epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)
            print(f"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}")

            if phase == 'val' and epoch_acc > best_acc:
                best_acc = epoch_acc
                best_model_wts = model.state_dict()

    print(f"\nHu·∫•n luy·ªán ho√†n t·∫•t sau {(time.time() - since) // 60:.0f}m {(time.time() - since) % 60:.0f}s")
    print(f"üèÜ Best val Acc: {best_acc:.4f}")
    model.load_state_dict(best_model_wts)
    return model

# === G·ªåI HU·∫§N LUY·ªÜN ===
trained_model = train_model(model, criterion, optimizer, scheduler, num_epochs=num_epochs)
